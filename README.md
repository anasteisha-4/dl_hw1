## Эксперимент 1

10 эпох:
![alt text](<1. 10 epochs.png>)

20 эпох:
![alt text](<1. 20 epochs.png>)

### Выводы по эксперименту 1:

На первых эпохах наблюдается значительное улучшение метрик (сильное снижение лосса и рост ROC-AUC), после 6-7 эпох темп улучшения значительно замедляется, но продолжается до 15-17 эпох.

В первой настройке (10 эпох) рост ROC-AUC и снижение лосса продолжаются до конца, при 20 эпохах также видно постепенное улучшение, но разница между 15-й и 20-й эпохами уже минимальна, при большем числе эпох возникает риск переобучения.

Оптимальное число эпох: около 15-17

## Эксперимент 2

![alt text](2.png)

### Выводы по эксперименту 2:

Во втором эксперименте, как и в первом, итоговые метрики ROC-AUC достигают около 0.9, при этом здесь из-за добавления блоков и увеличения hidden size обучение идёт менее равномерно по скорости, модель "разгоняется" медленнее, но после 4-5 эпох обучение идёт стабильнее


## Эксперимент 3

![alt text](3.png)

### Выводы по эксперименту 3:

Качество модели значительно улучшилось: уже на первой эпохе модель показывает Train ROC-AUC ≈ 0.82 и Val ROC-AUC ≈ 0.89, что значительно лучше по сравнению с предыдущими экспериментами. В итоге, к 15 эпохе достигается Val ROC-AUC ≈ 0.9272, что говорит о высоком качестве.
Благодаря skip connection и batch norm, модель быстро набирает хорошее качество уже в начале обучения. Улучшения по мере обучения становятся менее заметными, так как с первых эпох достигается высокий уровень.

## Эксперимент 4

p = 0.01
![alt text](<4. p = 0.01.png>)

p = 0.1
![alt text](<4. p = 0.1.png>)

p = 0.2
![alt text](<4. p = 0.2.png>)

p = 0.5
![alt text](<4. p = 0.5.png>)

p = 0.9
![alt text](<4. p = 0.9.png>)

### Выводы по эксперименту 4:

1. dropout_p = 0.01  
   Train Loss снижается с 0.3307 → 0.1961, Val Loss с 0.2648 → 0.1896, Val ROC-AUC достигает максимума 0.9292 на 14 эпохе.

   При p = 0.01 наблюдается наивысший итоговый Val ROC-AUC среди всех экспериментов (0.9292), небольшое значение dropout практически не влияет на обучение, позволяя добиться высокой производительности

2. dropout_p = 0.1  
   Train Loss снижается с 0.3260 → 0.2023, Val Loss с 0.2610 → 0.1921, Val ROC-AUC плавно и стабильно растет до 0.9278.
   Наиболее стабильное обучение: минимальные колебания Val Loss и ROC-AUC.

3. dropout_p = 0.2  
   Train Loss снижается с 0.3290 → 0.2065, Val Loss с 0.2683 → 0.1921, Val ROC-AUC достигает 0.9268.
   Медленное обучение: Val ROC-AUC растет слабее, чем при p=0.1.
   Больший разрыв между Train и Val Loss, чем у p=0.1

4. dropout_p = 0.5  
   Train Loss снижается с 0.3477 → 0.2203, Val Loss с 0.2700 → 0.2038, Val ROC-AUC достигает 0.9238.
   При p = 0.5 видны признаки недообучения: низкие ROC-AUC и высокий Val Loss даже на поздних эпохах.

5. dropout_p = 0.9  
   Train Loss снижается с 0.3896 → 0.2533, Val Loss с 0.3172 → 0.2329, Val ROC-AUC не превышает 0.9086.
   Сильное недообучение: крайне высокие потери и низкие ROC-AUC, Dropout "зашумляет" сеть, сильно усложняя обучение.

Итог: оптимальнее всего выбрать dropout_p = 0.1 как значение, обеспечивающее наиболее стабильное и качественное обучение

## Эксперимент 5

lr = 0.01, weight_decay = 0.1
![alt text](<5. lr = 0.01 weight_decay = 0.1.png>)

lr = 0.01, weight_decay = 0.01
![alt text](<5. lr = 0.01, weight_decay = 0.01.png>)

lr = 0.01, weight_decay = 0.001
![alt text](<5. lr = 0.01, weight_decay = 0.001.png>)

lr = 0.1, weight_decay = 0.1
![alt text](<5. lr = 0.1, weight_decay = 0.1.png>)

lr = 0.1, weight_decay = 0.01
![alt text](<5. lr = 0.1, weight_decay = 0.01.png>)

lr = 0.1, weight_decay = 0.001
![alt text](<5. lr = 0.1, weight_decay = 0.001.png>)

lr = 0.05, weight_decay = 0.1
![alt text](<5. lr = 0.05, weight_decay = 0.1.png>)

lr = 0.05, weight_decay = 0.01
![alt text](<5. lr = 0.05, weight_decay = 0.01.png>)

lr = 0.05, weight_decay = 0.001
![alt text](<5. lr = 0.05, weight_decay = 0.001.png>)

1. lr = 0.01  
   a) weight_decay = 0.1
   На первой эпохе показатели хорошие (Train ROC-AUC ≈ 0.879, Val ROC-AUC ≈ 0.893), но уже во второй эпохе наблюдается ухудшение – и ROC-AUC, и лоссы ухудшаются.
   Начиная с 3-й эпохи модель «застревает» – показатели постепенно падают и стабилизируются на уровне Train ROC-AUC ≈ 0.881–0.882 и Val ROC-AUC ≈ 0.883–0.884.
   Вывод: Слишком сильная регуляризация (λ=0.1) при низком lr приводит к недообучению.

   b) weight_decay = 0.01
   На первой эпохе показатели хорошие – Train ROC-AUC ≈ 0.8995, Val ROC-AUC ≈ 0.9215.
   Итоговые значения приближаются к Train ROC-AUC ≈ 0.923–0.924 и Val ROC-AUC ≈ 0.927–0.928

   Вывод: Умеренная регулярзация (λ=0.01) при lr=0.01 позволяет модели обучаться хорошо, но итоговые метрики немного уступают лучшим.

   c) weight_decay = 0.001
   Показатели на старте схожи с предыдущими вариантами – старт около 0.90/0.92.
   Модель демонстрирует устойчивый рост ROC-AUC, доходя до Epoch 12–14 до Train и Val ROC-AUC ≈ 0.93. 
   Итоговые метрики наилучшие: финальные значения – Train ROC-AUC ≈ 0.9314, Val ROC-AUC ≈ 0.9303, а лоссы ниже.

   Вывод: При lr=0.01 уменьшение weight decay до 0.001 даёт наилучший баланс между регуляризацией и способностью модели подстраиваться под данные.
   
2. lr = 0.1  
   a) weight_decay = 0.1
   Плохие стартовые показатели – Train ROC-AUC ≈ 0.8771, Val ROC-AUC ≈ 0.8813.
   Модель практически не улучшается, итоговые значения остаются низкими (Train ROC-AUC ≈ 0.8786, Val ROC-AUC ≈ 0.8855).
   Вывод: Слишком высокая скорость обучения в сочетании с агрессивной регуляризацией приводит к сильному недообучению.

   b) weight_decay = 0.01
   Начальные метрики хорошие (Train ROC-AUC ≈ 0.9077, Val ROC-AUC ≈ 0.9112), но затем наблюдаются скачки.
   Итоговые показатели остаются невысокими – примерно Train ROC-AUC ≈ 0.9100 и Val ROC-AUC ≈ 0.8968.
   Вывод: При lr=0.1 регуляризация с λ=0.01 не способна компенсировать слишком высокую скорость обучения, итоговое качество ниже, чем при более низком lr.

   c) weight_decay = 0.001
   Показатели стартуют на уровне Train ROC-AUC ≈ 0.9087, Val ROC-AUC ≈ 0.9019.
   Модель показывает неоднородное поведение: в некоторых эпохах наблюдаются резкие скачки, однако к концу обучения показатели стабилизируются – финальные значения Train и Val ROC-AUC ≈ 0.92-0.93.

   Вывод: Несмотря на нестабильность в процессе (что указывает на слишком высокую скорость обучения для данного случая), итоговые метрики могут быть конкурентоспособны, однако процесс обучения менее устойчив по сравнению с lr=0.01.

3. lr = 0.05  
   a) weight_decay = 0.1
   Уже с первой эпохи показатели хуже – Train ROC-AUC ≈ 0.8796, Val ROC-AUC ≈ 0.8842.
   Модель стабильно показывает низкие значения ROC-AUC (около 0.88) и не улучшается к концу – итоговые метрики около 0.8800–0.8850.
   Вывод: При достаточно высоком weight decay и lr=0.05 модель недообучается.

   b) weight_decay = 0.01
   Начальные значения неплохие – Train ROC-AUC около  0.909, Val ROC-AUC около 0.92, но уже во второй и третьей эпохах наблюдаются скачки
   Итоговые результаты не показывают улучшения модели – к концу ROC-AUC снижается до ~0.89 (Train) и ~0.902 (Val).
   Вывод: При lr=0.05 увеличение весового распада до 0.01 приводит к нестабильности и, в итоге, снижению качества.

   c) weight_decay = 0.001
   Начальные метрики схожи с предыдущими вариантами (Train ROC-AUC ≈ 0.892, Val ROC-AUC ≈ 0.910).
   Модель постепенно улучшает показатели до Epoch 3–5 (ROC-AUC достигает ≈ 0.907–0.912), но наблюдаются значительные скачки в значениях лосса (например, во 4-й и 6-й эпохах – Val Loss резко возрастает).
   Вывод: Хотя итоговые метрики (финальные Train ROC-AUC ≈ 0.9283, Val ROC-AUC ≈ 0.9311) сопоставимы с lr=0.01/λ=0.001, обучение происходит с заметной нестабильностью и скачками в потерях.


Выводы:

Learning Rate:

Низкий lr (0.01) обеспечивает стабильное и плавное улучшение метрик, позволяя модели достигнуть высоких значений ROC-AUC без скачков.

Увеличение lr может привести к ускоренному обучению, но часто сопровождается нестабильностью и даже ухудшением итоговых показателей, особенно в сочетании с агрессивным weight decay.

Weight Decay:

Слишком высокое значение (0.1) ведёт к сильной регуляризации, вызывая недообучение

Умеренные значения (0.01) дают стабильные результаты, но лучшие показатели получаются при минимальном weight decay (0.001) – особенно при lr=0.01, где достигаются самые высокие метрики (Val ROC-AUC около 0.925).
Однако при высоком lr (0.1) даже низкий weight decay может вызвать нестабильность в обучении.

Таким образом, итоговое качество модели и динамика обучения чувствительны как к lr, так и к weight decay: увеличение этих параметров либо приводит к переусложнению регуляризации и недообучению, либо к нестабильности при слишком высоком lr.

Итог: оптимальное сочетание параметров: lr = 0.01 и weight_decay = 0.001
